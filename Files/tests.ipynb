{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "98f01a51-8750-4d1a-bcb2-4961dd9c3783",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Íú±·¥õ…™ ü ü …™  Ä…™Íú±·¥á ‚ÄºÔ∏èüáÆüá≥  |  üá¶üá™\n",
      "24\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# The coded form of the text\n",
    "coded_text = r\"\\ua731\\u1d1b\\u026a\\u029f\\u029f \\u026a \\u0280\\u026a\\ua731\\u1d07 \\u203c\\ufe0f\\ud83c\\uddee\\ud83c\\uddf3  |  \\ud83c\\udde6\\ud83c\\uddea\"\n",
    "\n",
    "# Convert the coded text to the original text using json.loads()\n",
    "original_text = json.loads('\"' + coded_text.replace('\"', '\\\\\"') + '\"')\n",
    "\n",
    "# Print the original text\n",
    "print(original_text)\n",
    "print(len(original_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "014d0c91-9331-486f-a37f-8172cff0ce13",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "url = \"https://www.instagram.com/geoaudio/\"\n",
    "if url[0:26] == \"https://www.instagram.com/\":\n",
    "    username = url[26:-1]\n",
    "    print(username)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "6c98321a-f634-4025-9454-762bb5183fc9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://scontent-lga3-1.cdninstagram.com/v/t51.2885-19/335634708_204597838834554_5777916953614198724_n.jpg?stp=dst-jpg_s100x100&_nc_cat=110&ccb=1-7&_nc_sid=8ae9d6&_nc_ohc=xHUH8OkIl_0AX-7uEeD&_nc_ht=scontent-lga3-1.cdninstagram.com&oh=00_AfB8g7stqVBxB7aZPyqXIJAROFjbvwbrpzTbXDJJiDPQTQ&oe=645CADBE\n",
      "‚Ç¨terœÄa| B|!$$ ‚ú®\n",
      "‚ô™Mu$!¬¢‚ô™‚Ä¢‚Ä¢‚Ä¢W!th0ut Mu$!¬¢ L!fe W0u|d Be A M!$take ‚ô™‚ô™‚ô™\n",
      "# Att!tude !s a l!l th!ng that makes \n",
      "a b!g d!fference #\n",
      "üîí\n",
      "26\n"
     ]
    }
   ],
   "source": [
    "#grabbing bio \n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "\n",
    "# The URL of the Instagram profile\n",
    "url = \"https://www.instagram.com/blessy_k_s/\"\n",
    "\n",
    "# Send a GET request to the URL and get the HTML content\n",
    "response = requests.get(url)\n",
    "html_content = response.text\n",
    "\n",
    "# Parse the HTML content using BeautifulSoup\n",
    "soup = BeautifulSoup(html_content, \"html.parser\")\n",
    "\n",
    "# Find the <script> tag with type=\"application/ld+json\"\n",
    "script_tag = soup.find(\"script\", {\"type\": \"application/ld+json\"})\n",
    "\n",
    "#print(script_tag)\n",
    "\n",
    "# Extract the contents of the <script> tag\n",
    "json_data = json.loads(script_tag.contents[0])\n",
    "\n",
    "#print(json_data)\n",
    "\n",
    "#print(json.dumps(json_data, indent=2))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Extract the \"description\" key from the JSON data\n",
    "description = json_data[\"description\"]\n",
    "\n",
    "#checking for profile picture\n",
    "profile_img_url = json_data['author']['image']\n",
    "print(profile_img_url)\n",
    "if profile_img_url == \"\":\n",
    "    ppic = 0\n",
    "else:\n",
    "    ppic = 1\n",
    "# Print the description\n",
    "print(description)\n",
    "\n",
    "\n",
    "priv = json_data['interactionStatistic'][0]['userInteractionCount']\n",
    "\n",
    "print(priv)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "eca4c27b-d0d9-4e86-ae9f-86af9d8108b5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'text'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[90], line 10\u001b[0m\n\u001b[0;32m      7\u001b[0m response \u001b[38;5;241m=\u001b[39m requests\u001b[38;5;241m.\u001b[39mget(url)\n\u001b[0;32m      8\u001b[0m soup \u001b[38;5;241m=\u001b[39m BeautifulSoup(response\u001b[38;5;241m.\u001b[39mcontent, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhtml.parser\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 10\u001b[0m is_private \u001b[38;5;241m=\u001b[39m \u001b[43msoup\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mh2\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mclass\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrkEop\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtext\u001b[49m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThis Account is Private\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_private:\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis is a private account.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'text'"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "username = 'example_username'\n",
    "url = f'https://www.instagram.com/rajaprabhavr/'\n",
    "\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "is_private = soup.find('h2', {'class': 'rkEop'}).text == 'This Account is Private'\n",
    "if is_private:\n",
    "    print(\"This is a private account.\")\n",
    "else:\n",
    "    print(\"This is a public account.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d70da060-059f-409f-9f92-24aa226fb511",
   "metadata": {},
   "outputs": [],
   "source": [
    "#abandoned bs scrap \n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Replace with the username you want to scrape\n",
    "username = 'example_username'\n",
    "\n",
    "# Define the URL to scrape\n",
    "url = f'https://www.instagram.com/artistpng/'\n",
    "\n",
    "# Send a GET request to the URL\n",
    "response = requests.get(url)\n",
    "\n",
    "# Check if the request was successful\n",
    "if response.status_code == 200:\n",
    "    # Parse the HTML content using BeautifulSoup\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "    # Find the og:description meta tag\n",
    "    meta_tag = soup.find('meta', {'property': 'og:description'})\n",
    "\n",
    "    # Check if the meta tag was found before accessing its content attribute\n",
    "    if meta_tag:\n",
    "        content = meta_tag.get('content')\n",
    "\n",
    "        # Print the content to debug the issue\n",
    "        print(f\"Content: {content}\")\n",
    "\n",
    "        # Extract the follower count, following count, and number of posts from the content\n",
    "        parts = content.split(' - ')\n",
    "\n",
    "        # Print the parts list to debug the issue\n",
    "        print(f\"Parts: {parts}\")\n",
    "\n",
    "        followers = parts[0].split()[0]\n",
    "        following = parts[1].split()[0]\n",
    "        posts = parts[2].split()[0]\n",
    "\n",
    "        # Print out the public data\n",
    "        print(f\"Followers: {followers}\")\n",
    "        print(f\"Following: {following}\")\n",
    "        print(f\"Number of posts: {posts}\")\n",
    "    else:\n",
    "        print(\"Could not find the public data\")\n",
    "else:\n",
    "    # If the request was unsuccessful, print an error message\n",
    "    print(f\"Error: {response.status_code}\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "\"\"\"\n",
    "    # Check if the meta tag was found before accessing its content attribute\n",
    "    if meta_tag:\n",
    "        content = meta_tag.get('content')\n",
    "\n",
    "        # Extract the follower count, following count, and number of posts from the content\n",
    "        parts = content.split(' - ')\n",
    "\n",
    "        # Check if the parts list has at least three elements before trying to access the third element\n",
    "        if len(parts) >= 3:\n",
    "            followers = parts[0].split()[0]\n",
    "            following = parts[1].split()[0]\n",
    "            posts = parts[2].split()[0]\n",
    "\n",
    "            # Print out the public data\n",
    "            print(f\"Followers: {followers}\")\n",
    "            print(f\"Following: {following}\")\n",
    "            print(f\"Number of posts: {posts}\")\n",
    "        else:\n",
    "            print(\"Could not find the public data\")\n",
    "    else:\n",
    "        print(\"Could not find the public data\")\n",
    "else:\n",
    "    # If the request was unsuccessful, print an error message\n",
    "    print(f\"Error: {response.status_code}\")\n",
    "    \n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "14952c6a-b525-45e6-89df-2589a5c7a765",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'string'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[34], line 14\u001b[0m\n\u001b[0;32m     11\u001b[0m soup \u001b[38;5;241m=\u001b[39m BeautifulSoup(response\u001b[38;5;241m.\u001b[39mcontent, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhtml.parser\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Checking if the profile is private\u001b[39;00m\n\u001b[1;32m---> 14\u001b[0m is_private \u001b[38;5;241m=\u001b[39m \u001b[43msoup\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mh2\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mclass\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrkEop\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstring\u001b[49m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis Account is Private\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# Checking if the profile has a profile picture\u001b[39;00m\n\u001b[0;32m     17\u001b[0m has_profile_picture \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mbool\u001b[39m(soup\u001b[38;5;241m.\u001b[39mfind(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimg\u001b[39m\u001b[38;5;124m'\u001b[39m, {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclass\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbe6sR\u001b[39m\u001b[38;5;124m'\u001b[39m}))\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'string'"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Instagram profile URL\n",
    "url = \"https://www.instagram.com/artistpng/\"\n",
    "\n",
    "# Send GET request to the profile URL\n",
    "response = requests.get(url)\n",
    "\n",
    "# Parsing the HTML content using BeautifulSoup\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "# Checking if the profile is private\n",
    "is_private = soup.find('h2', {'class': 'rkEop'}).string == \"This Account is Private\"\n",
    "\n",
    "# Checking if the profile has a profile picture\n",
    "has_profile_picture = bool(soup.find('img', {'class': 'be6sR'}))\n",
    "\n",
    "print(\"Private account: \", is_private)\n",
    "print(\"Profile picture exists: \", has_profile_picture)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "726333fa-197f-4e7f-b156-fa5fdcf39d72",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "print(\"ok\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "466d894c-7336-4b9f-ae3d-917765cedb05",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This account is public\n"
     ]
    }
   ],
   "source": [
    "# working \n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "\n",
    "# Initialize the webdriver\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "# Open the Instagram account\n",
    "driver.get(\"https://www.instagram.com/microsoft/\")\n",
    "\n",
    "try:\n",
    "    # Wait for the account status element to appear\n",
    "    wait = WebDriverWait(driver, 10)\n",
    "    status_element = wait.until(EC.presence_of_element_located((By.XPATH, \"//h2[contains(text(),'This Account is Private')]\")))\n",
    "    \n",
    "    # Check if the account is private\n",
    "    if status_element:\n",
    "        print(\"This account is private\")\n",
    "except:\n",
    "    # If the account is public or there was an error, print the account is public\n",
    "    print(\"This account is public\")\n",
    "\n",
    "# Close the webdriver\n",
    "driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "21521180-9d69-453d-9842-e067bb4e2a7d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This account is public\n"
     ]
    }
   ],
   "source": [
    "# working \n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "\n",
    "\n",
    "# Create options for headless mode\n",
    "chrome_options = Options()\n",
    "chrome_options.add_argument('--headless')\n",
    "#chrome_options.add_argument('--disable-gpu')\n",
    "chrome_options.add_argument('--disable-blink-features=AutomationControlled')\n",
    "\n",
    "\n",
    "# Initialize the webdriver with headless mode\n",
    "driver = webdriver.Chrome(options=chrome_options)\n",
    "\n",
    "# Open the Instagram account\n",
    "driver.get(\"https://www.instagram.com/rajaprabhavr/\")\n",
    "\n",
    "try:\n",
    "    # Wait for the account status element to appear\n",
    "    wait = WebDriverWait(driver, 10)\n",
    "    status_element = wait.until(EC.presence_of_element_located((By.XPATH, \"//h2[contains(text(),'This Account is Private')]\")))\n",
    "    \n",
    "    # Check if the account is private\n",
    "    if status_element:\n",
    "        print(\"This account is private\")\n",
    "except:\n",
    "    # If the account is public or there was an error, print the account is public\n",
    "    print(\"This account is public\")\n",
    "\n",
    "# Close the webdriver\n",
    "driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "1e651d2a-e8c4-4bee-bda2-263dabffe0c3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "TimeoutException",
     "evalue": "Message: \nStacktrace:\nBacktrace:\n\tGetHandleVerifier [0x006FDCE3+50899]\n\t(No symbol) [0x0068E111]\n\t(No symbol) [0x00595588]\n\t(No symbol) [0x005C08F9]\n\t(No symbol) [0x005C0AFB]\n\t(No symbol) [0x005EF902]\n\t(No symbol) [0x005DB944]\n\t(No symbol) [0x005EE01C]\n\t(No symbol) [0x005DB6F6]\n\t(No symbol) [0x005B7708]\n\t(No symbol) [0x005B886D]\n\tGetHandleVerifier [0x00963EAE+2566302]\n\tGetHandleVerifier [0x009992B1+2784417]\n\tGetHandleVerifier [0x0099327C+2759788]\n\tGetHandleVerifier [0x00795740+672048]\n\t(No symbol) [0x00698872]\n\t(No symbol) [0x006941C8]\n\t(No symbol) [0x006942AB]\n\t(No symbol) [0x006871B7]\n\tBaseThreadInitThunk [0x771E7D49+25]\n\tRtlInitializeExceptionChain [0x77E3B74B+107]\n\tRtlClearBits [0x77E3B6CF+191]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTimeoutException\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[70], line 14\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Wait for the account status element to appear\u001b[39;00m\n\u001b[0;32m     13\u001b[0m wait \u001b[38;5;241m=\u001b[39m WebDriverWait(driver, \u001b[38;5;241m20\u001b[39m)\n\u001b[1;32m---> 14\u001b[0m status_element \u001b[38;5;241m=\u001b[39m \u001b[43mwait\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muntil\u001b[49m\u001b[43m(\u001b[49m\u001b[43mEC\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvisibility_of_element_located\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mBy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mXPATH\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/html/body/div[2]/div/div/div[1]/div/div/div/div[1]/div[2]/section/main/div/div[2]/article/div/div/h2\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# Check if the account is private\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m status_element\u001b[38;5;241m.\u001b[39mtext \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThis Account is Private\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "File \u001b[1;32mc:\\users\\geo joseph\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\selenium\\webdriver\\support\\wait.py:95\u001b[0m, in \u001b[0;36mWebDriverWait.until\u001b[1;34m(self, method, message)\u001b[0m\n\u001b[0;32m     93\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m time\u001b[38;5;241m.\u001b[39mmonotonic() \u001b[38;5;241m>\u001b[39m end_time:\n\u001b[0;32m     94\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m---> 95\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m TimeoutException(message, screen, stacktrace)\n",
      "\u001b[1;31mTimeoutException\u001b[0m: Message: \nStacktrace:\nBacktrace:\n\tGetHandleVerifier [0x006FDCE3+50899]\n\t(No symbol) [0x0068E111]\n\t(No symbol) [0x00595588]\n\t(No symbol) [0x005C08F9]\n\t(No symbol) [0x005C0AFB]\n\t(No symbol) [0x005EF902]\n\t(No symbol) [0x005DB944]\n\t(No symbol) [0x005EE01C]\n\t(No symbol) [0x005DB6F6]\n\t(No symbol) [0x005B7708]\n\t(No symbol) [0x005B886D]\n\tGetHandleVerifier [0x00963EAE+2566302]\n\tGetHandleVerifier [0x009992B1+2784417]\n\tGetHandleVerifier [0x0099327C+2759788]\n\tGetHandleVerifier [0x00795740+672048]\n\t(No symbol) [0x00698872]\n\t(No symbol) [0x006941C8]\n\t(No symbol) [0x006942AB]\n\t(No symbol) [0x006871B7]\n\tBaseThreadInitThunk [0x771E7D49+25]\n\tRtlInitializeExceptionChain [0x77E3B74B+107]\n\tRtlClearBits [0x77E3B6CF+191]\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "# Create a new Chrome instance\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "# Navigate to the Instagram account URL\n",
    "driver.get(\"https://www.instagram.com/creativekerala/\")\n",
    "\n",
    "# Wait for the account status element to appear\n",
    "wait = WebDriverWait(driver, 20)\n",
    "status_element = wait.until(EC.visibility_of_element_located((By.XPATH, '/html/body/div[2]/div/div/div[1]/div/div/div/div[1]/div[2]/section/main/div/div[2]/article/div/div/h2')))\n",
    "\n",
    "# Check if the account is private\n",
    "if status_element.text == 'This Account is Private':\n",
    "    print('The account is private.')\n",
    "else:\n",
    "    print('The account is public.')\n",
    "\n",
    "# Close the browser window\n",
    "driver.quit()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "69088a56-7580-4b10-93ed-2b624bda2f37",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scrapy in c:\\users\\geo joseph\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (2.8.0)\n",
      "Requirement already satisfied: service-identity>=18.1.0 in c:\\users\\geo joseph\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from scrapy) (21.1.0)\n",
      "Requirement already satisfied: Twisted>=18.9.0 in c:\\users\\geo joseph\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from scrapy) (22.10.0)\n",
      "Requirement already satisfied: zope.interface>=5.1.0 in c:\\users\\geo joseph\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from scrapy) (6.0)\n",
      "Requirement already satisfied: cssselect>=0.9.1 in c:\\users\\geo joseph\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from scrapy) (1.2.0)\n",
      "Requirement already satisfied: queuelib>=1.4.2 in c:\\users\\geo joseph\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from scrapy) (1.6.2)\n",
      "Requirement already satisfied: cryptography>=3.4.6 in c:\\users\\geo joseph\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from scrapy) (39.0.2)\n",
      "Requirement already satisfied: itemadapter>=0.1.0 in c:\\users\\geo joseph\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from scrapy) (0.7.0)\n",
      "Requirement already satisfied: pyOpenSSL>=21.0.0 in c:\\users\\geo joseph\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from scrapy) (23.0.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\geo joseph\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from scrapy) (47.1.0)\n",
      "Requirement already satisfied: protego>=0.1.15 in c:\\users\\geo joseph\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from scrapy) (0.2.1)\n",
      "Requirement already satisfied: tldextract in c:\\users\\geo joseph\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from scrapy) (3.4.0)\n",
      "Requirement already satisfied: parsel>=1.5.0 in c:\\users\\geo joseph\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from scrapy) (1.7.0)\n",
      "Requirement already satisfied: w3lib>=1.17.0 in c:\\users\\geo joseph\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from scrapy) (2.1.1)\n",
      "Requirement already satisfied: packaging in c:\\users\\geo joseph\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from scrapy) (23.0)\n",
      "Requirement already satisfied: PyDispatcher>=2.0.5 in c:\\users\\geo joseph\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from scrapy) (2.0.7)\n",
      "Requirement already satisfied: itemloaders>=1.0.1 in c:\\users\\geo joseph\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from scrapy) (1.0.6)\n",
      "Requirement already satisfied: lxml>=4.3.0 in c:\\users\\geo joseph\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from scrapy) (4.9.2)\n",
      "Requirement already satisfied: cffi>=1.12 in c:\\users\\geo joseph\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from cryptography>=3.4.6->scrapy) (1.15.1)\n",
      "Requirement already satisfied: jmespath>=0.9.5 in c:\\users\\geo joseph\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from itemloaders>=1.0.1->scrapy) (1.0.1)\n",
      "Requirement already satisfied: six in c:\\users\\geo joseph\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from protego>=0.1.15->scrapy) (1.16.0)\n",
      "Requirement already satisfied: pyasn1 in c:\\users\\geo joseph\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from service-identity>=18.1.0->scrapy) (0.4.8)\n",
      "Requirement already satisfied: attrs>=19.1.0 in c:\\users\\geo joseph\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from service-identity>=18.1.0->scrapy) (22.2.0)\n",
      "Requirement already satisfied: pyasn1-modules in c:\\users\\geo joseph\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from service-identity>=18.1.0->scrapy) (0.2.8)\n",
      "Requirement already satisfied: hyperlink>=17.1.1 in c:\\users\\geo joseph\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from Twisted>=18.9.0->scrapy) (21.0.0)\n",
      "Requirement already satisfied: constantly>=15.1 in c:\\users\\geo joseph\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from Twisted>=18.9.0->scrapy) (15.1.0)\n",
      "Requirement already satisfied: incremental>=21.3.0 in c:\\users\\geo joseph\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from Twisted>=18.9.0->scrapy) (22.10.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.5 in c:\\users\\geo joseph\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from Twisted>=18.9.0->scrapy) (4.5.0)\n",
      "Requirement already satisfied: twisted-iocpsupport<2,>=1.0.2 in c:\\users\\geo joseph\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from Twisted>=18.9.0->scrapy) (1.0.2)\n",
      "Requirement already satisfied: Automat>=0.8.0 in c:\\users\\geo joseph\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from Twisted>=18.9.0->scrapy) (22.10.0)\n",
      "Requirement already satisfied: requests>=2.1.0 in c:\\users\\geo joseph\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from tldextract->scrapy) (2.28.2)\n",
      "Requirement already satisfied: filelock>=3.0.8 in c:\\users\\geo joseph\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from tldextract->scrapy) (3.10.2)\n",
      "Requirement already satisfied: idna in c:\\users\\geo joseph\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from tldextract->scrapy) (3.4)\n",
      "Requirement already satisfied: requests-file>=1.4 in c:\\users\\geo joseph\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from tldextract->scrapy) (1.5.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\geo joseph\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from cffi>=1.12->cryptography>=3.4.6->scrapy) (2.21)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\geo joseph\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from requests>=2.1.0->tldextract->scrapy) (3.1.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\geo joseph\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from requests>=2.1.0->tldextract->scrapy) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\geo joseph\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from requests>=2.1.0->tldextract->scrapy) (2022.12.7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 23.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ipython in c:\\users\\geo joseph\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (8.11.0)\n",
      "Requirement already satisfied: traitlets>=5 in c:\\users\\geo joseph\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from ipython) (5.9.0)\n",
      "Requirement already satisfied: pickleshare in c:\\users\\geo joseph\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from ipython) (0.7.5)\n",
      "Requirement already satisfied: decorator in c:\\users\\geo joseph\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from ipython) (5.1.1)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30 in c:\\users\\geo joseph\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from ipython) (3.0.38)\n",
      "Requirement already satisfied: pygments>=2.4.0 in c:\\users\\geo joseph\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from ipython) (2.14.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\geo joseph\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from ipython) (0.4.6)\n",
      "Requirement already satisfied: backcall in c:\\users\\geo joseph\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from ipython) (0.2.0)\n",
      "Requirement already satisfied: stack-data in c:\\users\\geo joseph\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from ipython) (0.6.2)\n",
      "Requirement already satisfied: matplotlib-inline in c:\\users\\geo joseph\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from ipython) (0.1.6)\n",
      "Requirement already satisfied: jedi>=0.16 in c:\\users\\geo joseph\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from ipython) (0.18.2)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in c:\\users\\geo joseph\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from jedi>=0.16->ipython) (0.8.3)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\geo joseph\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30->ipython) (0.2.6)\n",
      "Requirement already satisfied: pure-eval in c:\\users\\geo joseph\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from stack-data->ipython) (0.2.2)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in c:\\users\\geo joseph\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from stack-data->ipython) (2.2.1)\n",
      "Requirement already satisfied: executing>=1.2.0 in c:\\users\\geo joseph\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from stack-data->ipython) (1.2.0)\n",
      "Requirement already satisfied: six in c:\\users\\geo joseph\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from asttokens>=2.1.0->stack-data->ipython) (1.16.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 23.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install scrapy\n",
    "!pip install ipython\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "35aeaff2-56dc-4135-a750-19b63e5c5742",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import scrapy\n",
    "\n",
    "class MySpider(scrapy.Spider):\n",
    "    name = 'myspider'\n",
    "    start_urls = ['https://example.com']\n",
    "\n",
    "    def parse(self, response):\n",
    "        # Extract information from the page using XPath selectors\n",
    "        title = response.xpath('//title/text()').get()\n",
    "        paragraphs = response.xpath('//p/text()').getall()\n",
    "\n",
    "        # Print the extracted data\n",
    "        print('Title:', title)\n",
    "        print('Paragraphs:', paragraphs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "19e67688-6816-401b-83d0-779d29e66a2e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-18 14:47:50 [scrapy.utils.log] INFO: Scrapy 2.8.0 started (bot: scrapybot)\n",
      "2023-04-18 14:47:50 [scrapy.utils.log] INFO: Versions: lxml 4.9.2.0, libxml2 2.9.12, cssselect 1.2.0, parsel 1.7.0, w3lib 2.1.1, Twisted 22.10.0, Python 3.8.5 (tags/v3.8.5:580fbb0, Jul 20 2020, 15:57:54) [MSC v.1924 64 bit (AMD64)], pyOpenSSL 23.0.0 (OpenSSL 3.0.8 7 Feb 2023), cryptography 39.0.2, Platform Windows-10-10.0.22621-SP0\n",
      "2023-04-18 14:47:50 [scrapy.crawler] INFO: Overridden settings:\n",
      "{}\n",
      "2023-04-18 14:47:50 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.selectreactor.SelectReactor\n",
      "2023-04-18 14:47:50 [scrapy.extensions.telnet] INFO: Telnet Password: 6f53de34ed49f5fe\n",
      "2023-04-18 14:47:50 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2023-04-18 14:47:50 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2023-04-18 14:47:50 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2023-04-18 14:47:50 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2023-04-18 14:47:50 [scrapy.core.engine] INFO: Spider opened\n",
      "2023-04-18 14:47:50 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2023-04-18 14:47:50 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6029\n"
     ]
    },
    {
     "ename": "ReactorNotRestartable",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mReactorNotRestartable\u001b[0m                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[108], line 23\u001b[0m\n\u001b[0;32m     20\u001b[0m     process\u001b[38;5;241m.\u001b[39mcrawl(MySpider)\n\u001b[0;32m     21\u001b[0m     process\u001b[38;5;241m.\u001b[39mstart(stop_after_crawl\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m---> 23\u001b[0m \u001b[43mrun_spider\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[108], line 21\u001b[0m, in \u001b[0;36mrun_spider\u001b[1;34m()\u001b[0m\n\u001b[0;32m     19\u001b[0m process \u001b[38;5;241m=\u001b[39m CrawlerProcess(get_project_settings())\n\u001b[0;32m     20\u001b[0m process\u001b[38;5;241m.\u001b[39mcrawl(MySpider)\n\u001b[1;32m---> 21\u001b[0m \u001b[43mprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstop_after_crawl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\users\\geo joseph\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\scrapy\\crawler.py:383\u001b[0m, in \u001b[0;36mCrawlerProcess.start\u001b[1;34m(self, stop_after_crawl, install_signal_handlers)\u001b[0m\n\u001b[0;32m    381\u001b[0m tp\u001b[38;5;241m.\u001b[39madjustPoolsize(maxthreads\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msettings\u001b[38;5;241m.\u001b[39mgetint(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mREACTOR_THREADPOOL_MAXSIZE\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m    382\u001b[0m reactor\u001b[38;5;241m.\u001b[39maddSystemEventTrigger(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbefore\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshutdown\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop)\n\u001b[1;32m--> 383\u001b[0m \u001b[43mreactor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43minstallSignalHandlers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\users\\geo joseph\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\twisted\\internet\\base.py:1317\u001b[0m, in \u001b[0;36m_SignalReactorMixin.run\u001b[1;34m(self, installSignalHandlers)\u001b[0m\n\u001b[0;32m   1316\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun\u001b[39m(\u001b[38;5;28mself\u001b[39m, installSignalHandlers: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1317\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstartRunning\u001b[49m\u001b[43m(\u001b[49m\u001b[43minstallSignalHandlers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minstallSignalHandlers\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1318\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmainLoop()\n",
      "File \u001b[1;32mc:\\users\\geo joseph\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\twisted\\internet\\base.py:1299\u001b[0m, in \u001b[0;36m_SignalReactorMixin.startRunning\u001b[1;34m(self, installSignalHandlers)\u001b[0m\n\u001b[0;32m   1290\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1291\u001b[0m \u001b[38;5;124;03mExtend the base implementation in order to remember whether signal\u001b[39;00m\n\u001b[0;32m   1292\u001b[0m \u001b[38;5;124;03mhandlers should be installed later.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1296\u001b[0m \u001b[38;5;124;03m    installed during startup.\u001b[39;00m\n\u001b[0;32m   1297\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1298\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_installSignalHandlers \u001b[38;5;241m=\u001b[39m installSignalHandlers\n\u001b[1;32m-> 1299\u001b[0m \u001b[43mReactorBase\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstartRunning\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mReactorBase\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\users\\geo joseph\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\twisted\\internet\\base.py:843\u001b[0m, in \u001b[0;36mReactorBase.startRunning\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    841\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m error\u001b[38;5;241m.\u001b[39mReactorAlreadyRunning()\n\u001b[0;32m    842\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_startedBefore:\n\u001b[1;32m--> 843\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m error\u001b[38;5;241m.\u001b[39mReactorNotRestartable()\n\u001b[0;32m    844\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_started \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    845\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stopped \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[1;31mReactorNotRestartable\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from scrapy.crawler import CrawlerProcess\n",
    "\n",
    "process = CrawlerProcess()\n",
    "process.crawl(MySpider)\n",
    "process.start()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "e12840ee-6b80-494d-be29-67e8220af2a7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-21 15:19:56 [urllib3.connectionpool] DEBUG: Starting new HTTPS connection (1): www.instagram.com:443\n",
      "2023-04-21 15:19:57 [urllib3.connectionpool] DEBUG: https://www.instagram.com:443 \"GET /api/v1/users/web_profile_info/?username=rajaprabhavr HTTP/1.1\" 200 1171\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "{\n",
      " \"data\": {\n",
      "  \"user\": {\n",
      "   \"biography\": \"\\u2728I am fearless  out of everything\\u2728\\n\\u2601\\ufe0fNephophile\\ud83c\\udf28\\ufe0f\\ud83d\\udcad\\n#exnaipunnyan\\n#RITian\",\n",
      "   \"bio_links\": [],\n",
      "   \"biography_with_entities\": {\n",
      "    \"raw_text\": \"\\u2728I am fearless  out of everything\\u2728\\n\\u2601\\ufe0fNephophile\\ud83c\\udf28\\ufe0f\\ud83d\\udcad\\n#exnaipunnyan\\n#RITian\",\n",
      "    \"entities\": [\n",
      "     {\n",
      "      \"user\": null,\n",
      "      \"hashtag\": {\n",
      "       \"name\": \"ritian\"\n",
      "      }\n",
      "     },\n",
      "     {\n",
      "      \"user\": null,\n",
      "      \"hashtag\": {\n",
      "       \"name\": \"exnaipunnyan\"\n",
      "      }\n",
      "     }\n",
      "    ]\n",
      "   },\n",
      "   \"blocked_by_viewer\": false,\n",
      "   \"restricted_by_viewer\": null,\n",
      "   \"country_block\": false,\n",
      "   \"external_url\": null,\n",
      "   \"external_url_linkshimmed\": null,\n",
      "   \"edge_followed_by\": {\n",
      "    \"count\": 343\n",
      "   },\n",
      "   \"fbid\": \"17841439286896726\",\n",
      "   \"followed_by_viewer\": false,\n",
      "   \"edge_follow\": {\n",
      "    \"count\": 714\n",
      "   },\n",
      "   \"follows_viewer\": false,\n",
      "   \"full_name\": \"Rajaprabha V R\",\n",
      "   \"group_metadata\": null,\n",
      "   \"has_ar_effects\": false,\n",
      "   \"has_clips\": false,\n",
      "   \"has_guides\": false,\n",
      "   \"has_channel\": false,\n",
      "   \"has_blocked_viewer\": false,\n",
      "   \"highlight_reel_count\": 0,\n",
      "   \"has_requested_viewer\": false,\n",
      "   \"hide_like_and_view_counts\": false,\n",
      "   \"id\": \"39173813563\",\n",
      "   \"is_business_account\": false,\n",
      "   \"is_professional_account\": false,\n",
      "   \"is_supervision_enabled\": false,\n",
      "   \"is_guardian_of_viewer\": false,\n",
      "   \"is_supervised_by_viewer\": false,\n",
      "   \"is_supervised_user\": false,\n",
      "   \"is_embeds_disabled\": false,\n",
      "   \"is_joined_recently\": false,\n",
      "   \"guardian_id\": null,\n",
      "   \"business_address_json\": null,\n",
      "   \"business_contact_method\": \"UNKNOWN\",\n",
      "   \"business_email\": null,\n",
      "   \"business_phone_number\": null,\n",
      "   \"business_category_name\": null,\n",
      "   \"overall_category_name\": null,\n",
      "   \"category_enum\": null,\n",
      "   \"category_name\": null,\n",
      "   \"is_private\": true,\n",
      "   \"is_verified\": false,\n",
      "   \"edge_mutual_followed_by\": {\n",
      "    \"count\": 0,\n",
      "    \"edges\": []\n",
      "   },\n",
      "   \"profile_pic_url\": \"https://instagram.fmaa8-1.fna.fbcdn.net/v/t51.2885-19/324552228_700570771601469_2152019917423506392_n.jpg?stp=dst-jpg_s150x150&_nc_ht=instagram.fmaa8-1.fna.fbcdn.net&_nc_cat=109&_nc_ohc=eiu2zWeR354AX_bhRYZ&edm=AOQ1c0wBAAAA&ccb=7-5&oh=00_AfBG9GU96YLjtXcb11XcC6YWa87dQjDgp15DrBcE57c98g&oe=64483D55&_nc_sid=8fd12b\",\n",
      "   \"profile_pic_url_hd\": \"https://instagram.fmaa8-1.fna.fbcdn.net/v/t51.2885-19/324552228_700570771601469_2152019917423506392_n.jpg?stp=dst-jpg_s320x320&_nc_ht=instagram.fmaa8-1.fna.fbcdn.net&_nc_cat=109&_nc_ohc=eiu2zWeR354AX_bhRYZ&edm=AOQ1c0wBAAAA&ccb=7-5&oh=00_AfCN3zaEIur5KRlLYB6mzsOdobzmJMXAJBJx61v_SYqHHw&oe=64483D55&_nc_sid=8fd12b\",\n",
      "   \"requested_by_viewer\": false,\n",
      "   \"should_show_category\": false,\n",
      "   \"should_show_public_contacts\": false,\n",
      "   \"show_account_transparency_details\": null,\n",
      "   \"transparency_label\": null,\n",
      "   \"transparency_product\": \"STATE_CONTROLLED_MEDIA\",\n",
      "   \"username\": \"rajaprabhavr\",\n",
      "   \"connected_fb_page\": null,\n",
      "   \"pronouns\": [],\n",
      "   \"edge_felix_video_timeline\": {\n",
      "    \"count\": 0,\n",
      "    \"page_info\": {\n",
      "     \"has_next_page\": false,\n",
      "     \"end_cursor\": null\n",
      "    },\n",
      "    \"edges\": []\n",
      "   },\n",
      "   \"edge_owner_to_timeline_media\": {\n",
      "    \"count\": 0,\n",
      "    \"page_info\": {\n",
      "     \"has_next_page\": false,\n",
      "     \"end_cursor\": null\n",
      "    },\n",
      "    \"edges\": []\n",
      "   },\n",
      "   \"edge_saved_media\": {\n",
      "    \"count\": 0,\n",
      "    \"page_info\": {\n",
      "     \"has_next_page\": false,\n",
      "     \"end_cursor\": null\n",
      "    },\n",
      "    \"edges\": []\n",
      "   },\n",
      "   \"edge_media_collections\": {\n",
      "    \"count\": 0,\n",
      "    \"page_info\": {\n",
      "     \"has_next_page\": false,\n",
      "     \"end_cursor\": null\n",
      "    },\n",
      "    \"edges\": []\n",
      "   },\n",
      "   \"edge_related_profiles\": {\n",
      "    \"edges\": []\n",
      "   }\n",
      "  }\n",
      " },\n",
      " \"status\": \"ok\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "headers = {\"User-Agent\": \"Instagram 277.0.0.17.107 Android\"}\n",
    "username = \"rajaprabhavr\"\n",
    "response = requests.get(f\"https://www.instagram.com/api/v1/users/web_profile_info/?username={username}\", headers=headers)\n",
    "if response.status_code in [200, 201]:\n",
    "    # user actually exists\n",
    "    x = response.json()\n",
    "    is_private = x[\"data\"][\"user\"][\"is_private\"]\n",
    "    print(is_private)\n",
    "    print(json.dumps(x,indent=1))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
